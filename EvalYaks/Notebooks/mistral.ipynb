{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IclMOdyYFWBi","executionInfo":{"status":"ok","timestamp":1708408557476,"user_tz":-330,"elapsed":24007,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}},"outputId":"616b7af5-1a93-44c1-cf06-2577cf22e16a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cd /content/drive/MyDrive/Content & Curriculum/Dialogue Module/Evaluator/Dataset/B2/"],"metadata":{"id":"4LDlGqYYQ4kc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQ7IiixDRJG9","executionInfo":{"status":"ok","timestamp":1708411672744,"user_tz":-330,"elapsed":466,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}},"outputId":"14a98a18-90e1-4f24-8bed-65a1984270ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  mistral-ty-cefr\tsample_data  train.csv\n"]}]},{"cell_type":"code","source":["!pip install -q autoawq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9P593x3RfGv","executionInfo":{"status":"ok","timestamp":1708411727823,"user_tz":-330,"elapsed":13303,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}},"outputId":"0eb564b8-2576-45e8-8e23-1092f2e93c83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting autoawq\n","  Downloading autoawq-0.2.2-cp310-cp310-manylinux2014_x86_64.whl (76 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from autoawq) (2.1.0+cu121)\n","Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.10/dist-packages (from autoawq) (4.37.0)\n","Requirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from autoawq) (0.15.2)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from autoawq) (4.9.0)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from autoawq) (2.1.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from autoawq) (0.26.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from autoawq) (2.14.7)\n","Collecting zstandard (from autoawq)\n","  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting autoawq-kernels (from autoawq)\n","  Downloading autoawq_kernels-0.0.5-cp310-cp310-manylinux2014_x86_64.whl (29.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.12.1->autoawq) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (2023.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (2.31.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (4.65.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->autoawq) (5.9.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (0.70.15)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (3.9.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->autoawq) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->autoawq) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->autoawq) (2023.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->autoawq) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->autoawq) (1.16.0)\n","Installing collected packages: zstandard, autoawq-kernels, autoawq\n","Successfully installed autoawq-0.2.2 autoawq-kernels-0.0.5 zstandard-0.22.0\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ioJGhXFbt1Kw","outputId":"14f3aec9-9d76-4095-8432-190a097830be","executionInfo":{"status":"ok","timestamp":1708407900898,"user_tz":-330,"elapsed":8,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Feb 20 05:45:00 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   62C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"N67hcbyms8S5"},"source":["### Setup Runtime\n","For fine-tuning Llama, a GPU instance is essential. Follow the directions below:\n","\n","1. Go to `Runtime` (located in the top menu bar).\n","2. Select `Change Runtime Type`.\n","3. Choose `T4 GPU` (or a comparable option).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uGEQsNus8S6"},"outputs":[],"source":["!pip install -q pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"14J5dl5Ss8S8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708408036130,"user_tz":-330,"elapsed":85444,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}},"outputId":"96829f0c-38db-4f60-e0f0-a78f74ff440d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.5/226.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q autotrain-advanced"]},{"cell_type":"markdown","metadata":{"id":"yjwGgu_Is8S8"},"source":["### Setup Autotrain\n","The step below is required for AutoTrain in Colab\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRZudTTXs8S8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"49da0f70-e0a3-4a08-e651-d8ca29e146b7","executionInfo":{"status":"ok","timestamp":1708408060079,"user_tz":-330,"elapsed":23963,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["> \u001b[1mINFO    Installing latest xformers\u001b[0m\n","> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n","> \u001b[1mINFO    Installing latest PyTorch\u001b[0m\n","> \u001b[1mINFO    Successfully installed latest PyTorch\u001b[0m\n"]}],"source":["!autotrain setup --update-torch"]},{"cell_type":"markdown","metadata":{"id":"BJV_6i9Ss8S9"},"source":["### Connect to Hugging Face for model upload\n","#### Logging to Hugging Face\n","\n","To make sure the model can be uploaded to be used for Inference, it's necessary to log in to the Hugging Face hub.\n","\n","#### Getting a Hugging Face token\n","Steps:\n","1. Navigate to this URL: https://huggingface.co/settings/tokens\n","2. Create a `write` token and copy it to your clipboard\n","3. Run the code below and enter your token\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i2INc0xys8S-","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["364cc129003c4f22b73efda24ee932e8","3154519134bd4c2291b84379065c5d92","baff13b3318745e0b6e086851fe67f9f","5a4e72c08e6744d7879c471134c61013","36af42c83c71419c87c31746e9c91d7e","ae0a697605af46b49bd5b96bb794906c","95da5740ec164a35aa8db658dde00d85","cf032ff202ad437a818a8467f143ac84","715812fc6e7943e68a5c71200685fd31","7a7ebd1b72a74aa98324440fd064fe7c","6512b4993a4d468f932e62af2e2a99d6","a7c92d9aebb2406fadc1d974da558db4","18d3379e32fc451cbf9f86e6344d1108","a69926e3af894707807da9c769e16d50","a47a3276774f4d2081bd342049c8b8aa","0eb6ca866b7f416ab7d7fda966e8c3e8","6684b1f042d144409b2acd3a7004a045","653f7abbb89c40889afc7fa8a0ed0683","53a9f06bca064525a81aa6396af16f0a","bf534e14402d4a0b80d86c323aa233e0","9f166a05b3d346f69ff4024fa61777bc","46abd6e14b70419493aa67fe41e70899","995ad5d6ff2b4f83969527c9532e1297","3bd47c4983714045885441e0ebd4bdd5","f3ee70be37c541809d9a885b86a88bd2","70a3f0ad705d4d8d98b76f0c03cb1d46","c5a46308a912423190947bd15f96eeb7","c094178f63aa4044b7d20e74d1d8b1c8","5910058794024559a5ecc65acc013f97"]},"outputId":"420386b3-5e75-4f31-9e41-c7d4af795f7f","executionInfo":{"status":"ok","timestamp":1708409032453,"user_tz":-330,"elapsed":6,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"364cc129003c4f22b73efda24ee932e8"}},"metadata":{}}],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"markdown","metadata":{"id":"NRJUKq0Ss8S-"},"source":["### Upload your dataset\n","Add your data set to the root directory in the Colab under the name `train.csv`. The AutoTrain command will look for your data there under that name.\n","\n","##### Don't have a data set and want to try finetuning on an example data set?\n","If you don't have a dataset you can run these commands below to get an example data set and save it to `train.csv`\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/Content & Curriculum/Dialogue Module/Evaluator/Dataset/B2/train.csv\")\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":4588},"id":"eCPsREHBuxyr","outputId":"e1552c11-403d-42db-b124-0c01fa52f2ac","executionInfo":{"status":"ok","timestamp":1708408607115,"user_tz":-330,"elapsed":1956,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  text\n","0    ###Human:\\n\\n- You are an assessor of the Camb...\n","1    ###Human:\\n\\n- You are an assessor of the Camb...\n","2    ###Human:\\n\\n- You are an assessor of the Camb...\n","3    ###Human:\\n\\n- You are an assessor of the Camb...\n","4    ###Human:\\n\\n- You are an assessor of the Camb...\n","..                                                 ...\n","565  ###Human:\\n\\n- You are an assessor of the Camb...\n","566  ###Human:\\n\\n- You are an assessor of the Camb...\n","567  ###Human:\\n\\n- You are an assessor of the Camb...\n","568  ###Human:\\n\\n- You are an assessor of the Camb...\n","569  ###Human:\\n\\n- You are an assessor of the Camb...\n","\n","[570 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-fc132e9d-a52b-4160-82ea-a2e6bf2fd8b4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","    <tr>\n","      <th>569</th>\n","      <td>###Human:\\n\\n- You are an assessor of the Camb...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>570 rows × 1 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc132e9d-a52b-4160-82ea-a2e6bf2fd8b4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fc132e9d-a52b-4160-82ea-a2e6bf2fd8b4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fc132e9d-a52b-4160-82ea-a2e6bf2fd8b4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-435ca1c8-3759-40c4-8d69-70a725720547\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-435ca1c8-3759-40c4-8d69-70a725720547')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-435ca1c8-3759-40c4-8d69-70a725720547 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 570,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"###Human:\\n\\n- You are an assessor of the Cambridge B2 First English Assessment. You are an expert in this with several years of experience.\\n- You will be given a conversation between an examiner and a candidate.\\n- Your task is to give scores for two metrics along with reasons for the given scores and to list the grammar skills used in the conversation.\\n- Please make sure you read and understand these instructions carefully.\\n\\nEvaluation Steps:\\n\\n- Read the conversation between the examiner and the candidate carefully.\\n- Assign a score for GRAMMAR_AND_VOCABULARY and  DISCOURSE_MANAGEMENT on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.\\n- Provide three points explaining the rationale behind the scores assigned to GRAMMAR_AND_VOCABULARY and DISCOURSE_MANAGEMENT as values in an array format for the key REASON.\\n- List all the Grammar Skills used by the Candidate under the GRAMMAR_SKILLS_USED.\\n- Present the evaluation categories and scores in JSON format and name it OUTPUT. \\n\\nConversation: \\n\\n[{\\\"Examiner\\\": \\\"Can you tell me about the most difficult job you think there is?\\\", \\\"Candidate\\\": \\\"Working as firefighter can be very tough. It's because of the risk from fires.\\\"}, {\\\"Examiner\\\": \\\"Why do you think being a firefighter is difficult?\\\", \\\"Candidate\\\": \\\"Firefighter need to be brave. They fight with fire and sometimes save the people.\\\"}, {\\\"Examiner\\\": \\\"Do you have any plans for this weekend?\\\", \\\"Candidate\\\": \\\"Yes, I am planning to spend time in the park with my close friends for relaxation.\\\"}, {\\\"Examiner\\\": \\\"What will you do at the park?\\\", \\\"Candidate\\\": \\\"We'll probably take a long walk and enjoy the fresh air. Might also play some casual sports.\\\"}]\\n\\n###Assistant:\\n\\n {'GRAMMAR_AND_VOCABULARY': 2, 'DISCOURSE_MANAGEMENT': 4, 'REASON': ['The candidate makes several grammatical errors and uses basic vocabulary.', 'Responses are well-connected and detailed, showing a good level of discourse management.'], 'GRAMMAR_SKILLS_USED': [\\\"Future continuous ('I am planning to spend')\\\", \\\"Modal 'might' for possibility ('Might also play')\\\"]}\",\n          \"###Human:\\n\\n- You are an assessor of the Cambridge B2 First English Assessment. You are an expert in this with several years of experience.\\n- You will be given a conversation between an examiner and a candidate.\\n- Your task is to give scores for two metrics along with reasons for the given scores and to list the grammar skills used in the conversation.\\n- Please make sure you read and understand these instructions carefully.\\n\\nEvaluation Steps:\\n\\n- Read the conversation between the examiner and the candidate carefully.\\n- Assign a score for GRAMMAR_AND_VOCABULARY and  DISCOURSE_MANAGEMENT on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.\\n- Provide three points explaining the rationale behind the scores assigned to GRAMMAR_AND_VOCABULARY and DISCOURSE_MANAGEMENT as values in an array format for the key REASON.\\n- List all the Grammar Skills used by the Candidate under the GRAMMAR_SKILLS_USED.\\n- Present the evaluation categories and scores in JSON format and name it OUTPUT. \\n\\nConversation: \\n\\n[{\\\"Examiner\\\": \\\"Shyam, what draws you to your preferred subjects?\\\", \\\"Candidate\\\": \\\"The intricacies of human behavior and the mind's mysteries enthrall me, offering a window into our own nature. Mathematics, however, sometimes seems too rigid.\\\"}, {\\\"Examiner\\\": \\\"Where do you find peace for studying?\\\", \\\"Candidate\\\": \\\"I'm most at peace in a sunlit corner of my home, with a cup of tea and my notes spread out before me.\\\"}, {\\\"Examiner\\\": \\\"Is shopping a hobby for you?\\\", \\\"Candidate\\\": \\\"Certainly, especially when it comes to collecting vintage records and exploring music from different eras.\\\"}, {\\\"Examiner\\\": \\\"Describe your fitness routine.\\\", \\\"Candidate\\\": \\\"I engage in swimming and yoga, aiming for a balanced approach to physical and mental well-being.\\\"}]\\n\\n###Assistant:\\n\\n {'GRAMMAR_AND_VOCABULARY': 4, 'DISCOURSE_MANAGEMENT': 5, 'REASON': ['The candidate uses advanced vocabulary and complex grammar, with responses that are highly coherent and detailed.'], 'GRAMMAR_SKILLS_USED': [\\\"Relative clauses ('The intricacies of human behavior... that enthrall me')\\\", \\\"Present continuous for current actions ('I'm most at peace')\\\"]}\",\n          \"###Human:\\n\\n- You are an assessor of the Cambridge B2 First English Assessment. You are an expert in this with several years of experience.\\n- You will be given a conversation between an examiner and a candidate.\\n- Your task is to give scores for two metrics along with reasons for the given scores and to list the grammar skills used in the conversation.\\n- Please make sure you read and understand these instructions carefully.\\n\\nEvaluation Steps:\\n\\n- Read the conversation between the examiner and the candidate carefully.\\n- Assign a score for GRAMMAR_AND_VOCABULARY and  DISCOURSE_MANAGEMENT on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.\\n- Provide three points explaining the rationale behind the scores assigned to GRAMMAR_AND_VOCABULARY and DISCOURSE_MANAGEMENT as values in an array format for the key REASON.\\n- List all the Grammar Skills used by the Candidate under the GRAMMAR_SKILLS_USED.\\n- Present the evaluation categories and scores in JSON format and name it OUTPUT. \\n\\nConversation: \\n\\n[{\\\"Examiner\\\": \\\"How many people are there in your family, Anil?\\\", \\\"Candidate\\\": \\\"In family, we are four. I, my father, mother, and one brother.\\\"}, {\\\"Examiner\\\": \\\"Which festival do you all celebrate together, Anil?\\\", \\\"Candidate\\\": \\\"We all together celebrate Lohri. It very joyful.\\\"}, {\\\"Examiner\\\": \\\"What hobby do you enjoy, Anil?\\\", \\\"Candidate\\\": \\\"I very much enjoy playing the harmonium.\\\"}, {\\\"Examiner\\\": \\\"Do you plan to learn something new, Anil?\\\", \\\"Candidate\\\": \\\"Yes, planning for learn yoga. It interesting.\\\"}]\\n\\n###Assistant:\\n\\n {'GRAMMAR_AND_VOCABULARY': 1, 'DISCOURSE_MANAGEMENT': 3, 'REASON': ['Shows basic control of simple grammatical forms with significant errors, limited vocabulary.', 'Able to provide more information and extend responses, showing better discourse management.', 'Uses basic cohesive devices, contributing to the coherence of the discourse despite grammatical inaccuracies.'], 'GRAMMAR_SKILLS_USED': ['Simple present tense', 'Basic vocabulary with errors', 'Attempts at complex sentences']}\"\n        ],\n        \"num_unique_values\": 565,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["df['text'][13]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"id":"y1-8VyCiu6XX","outputId":"7ed2785c-3978-409d-98a8-b30514df283e","executionInfo":{"status":"ok","timestamp":1708408647791,"user_tz":-330,"elapsed":403,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'###Human:\\n\\n- You are an assessor of the Cambridge B2 First English Assessment. You are an expert in this with several years of experience.\\n- You will be given a conversation between an examiner and a candidate.\\n- Your task is to give scores for two metrics along with reasons for the given scores and to list the grammar skills used in the conversation.\\n- Please make sure you read and understand these instructions carefully.\\n\\nEvaluation Steps:\\n\\n- Read the conversation between the examiner and the candidate carefully.\\n- Assign a score for GRAMMAR_AND_VOCABULARY and  DISCOURSE_MANAGEMENT on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.\\n- Provide three points explaining the rationale behind the scores assigned to GRAMMAR_AND_VOCABULARY and DISCOURSE_MANAGEMENT as values in an array format for the key REASON.\\n- List all the Grammar Skills used by the Candidate under the GRAMMAR_SKILLS_USED.\\n- Present the evaluation categories and scores in JSON format and name it OUTPUT. \\n\\nConversation: \\n\\n[{\"Examiner\": \"How do you like to spend your evenings?\", \"Candidate\": \"My evenings are typically spent either engaging in a game of cricket with friends or delving into various genres of literature.\"}, {\"Examiner\": \"Do you normally celebrate special occasions with friends or family?\", \"Candidate\": \"Indeed, special occasions are primarily family-centric for us, where we come together to share in the joy, often over a lavish meal and heartwarming conversations.\"}, {\"Examiner\": \"How much TV do you watch in a week?\", \"Candidate\": \"My weekly television consumption is quite restrained, seldom exceeding a few hours, as I predominantly prefer activities that are more interactive or intellectually stimulating.\"}, {\"Examiner\": \"Tell us about a festival in your country.\", \"Candidate\": \"Diwali, the illustrious festival of lights in our country, is celebrated with great fervor, characterized by the lighting of lamps, exchange of sweets, and communal prayers, symbolizing the triumph of light over darkness.\"}]\\n\\n###Assistant:\\n\\n {\\'GRAMMAR_AND_VOCABULARY\\': 4, \\'DISCOURSE_MANAGEMENT\\': 4, \\'REASON\\': [\\'Candidate demonstrates a high level of grammatical accuracy with a wide range of vocabulary.\\', \\'The discourse is well-structured and coherent, with effective use of cohesive devices and clear development of ideas.\\', \\'Responses are detailed, with a clear progression of ideas and appropriate use of discourse markers.\\'], \\'GRAMMAR_SKILLS_USED\\': [\\'Complex Sentences\\', \\'Conditionals\\', \\'Modality\\']}'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"GQC62hD9s8S_"},"source":["## Overview of AutoTrain command\n","\n","#### Short overview of what the command flags do.\n","\n","- `!autotrain`: Command executed in environments like a Jupyter notebook to run shell commands directly. `autotrain` is an automatic training utility.\n","\n","- `llm`: A sub-command or argument specifying the type of task\n","\n","- `--train`: Initiates the training process.\n","\n","- `--project_name`: Sets the name of the project\n","\n","- `--model abhishek/llama-2-7b-hf-small-shards`: Specifies original model that is hosted on Hugging Face named \"llama-2-7b-hf-small-shards\" under the \"abhishek\".\n","\n","- `--data_path .`: The path to the dataset for training. The \".\" refers to the current directory. The `train.csv` file needs to be located in this directory.\n","\n","- `--use_int4`: Use of INT4 quantization to reduce model size and speed up inference times at the cost of some precision.\n","\n","- `--learning_rate 2e-4`: Sets the learning rate for training to 0.0002.\n","\n","- `--train_batch_size 12`: Sets the batch size for training to 12.\n","\n","- `--num_train_epochs 3`: The training process will iterate over the dataset 3 times.\n","\n","### Steps needed before running\n","Go to the `!autotrain` code cell below and update it by following the steps below:\n","\n","1. After `--project_name` replace `*enter-a-project-name*` with the name that you'd like to call the project\n","2. After `--repo_id` replace `*username*/*repository*`. Replace `*username*` with your Hugging Face username and `*repository*` with the repository name you'd like it to be created under. You don't need to create this repository before hand, it will automatically be created and uploaded once the training is completed.\n","3. Confirm that `train.csv` is in the root directory in the Colab. The `--data_path .` flag will make it so that AutoTrain looks for your data there.\n","4. Make sure to add the LoRA Target Modules to be trained `--target-modules q_proj, v_proj`\n","5. Once you've made these changes you're all set, run the command below!\n","\n","\n"]},{"cell_type":"code","source":["!autotrain llm --train --project-name mistral-ty-cefr --model TheBloke/Mistral-7B-Instruct-v0.2-AWQ --data-path . --peft --lr 2e-4 --train-batch-size 12 --epochs 3 --trainer sft --push-to-hub --repo-id auroresearch/mistral-ty-cefr --token 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"],"metadata":{"id":"9iGMc1JjS0MP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!autotrain llm --train --project-name mistral-ty-cefr --model filipealmeida/Mistral-7B-Instruct-v0.1-sharded --data-path . --peft --lr 2e-4 --train-batch-size 12 --epochs 3 --trainer sft --target-modules q_proj,v_proj --push-to-hub --repo-id auroresearch/mistral-ty-cefr --token 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"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCCSK2AbGBQQ","executionInfo":{"status":"ok","timestamp":1708417136470,"user_tz":-330,"elapsed":194433,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}},"outputId":"dd1becf3-3470-43de-8aae-aa339d5931ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["> \u001b[1mINFO    Running LLM\u001b[0m\n","> \u001b[1mINFO    Params: Namespace(version=False, text_column='text', rejected_text_column='rejected', prompt_text_column='prompt', model_ref=None, warmup_ratio=0.1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, add_eos_token=False, block_size=-1, peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, mixed_precision=None, quantization=None, model_max_length=1024, trainer='sft', target_modules='q_proj,v_proj', merge_adapter=False, use_flash_attention_2=False, dpo_beta=0.1, apply_chat_template=False, padding=None, train=True, deploy=False, inference=False, username=None, backend='local-cli', token='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', repo_id='auroresearch/mistral-ty-cefr', push_to_hub=True, model='filipealmeida/Mistral-7B-Instruct-v0.1-sharded', project_name='mistral-ty-cefr', seed=42, epochs=3, gradient_accumulation=1, disable_gradient_checkpointing=False, lr=0.0002, log='none', data_path='.', train_split='train', valid_split=None, batch_size=12, func=<function run_llm_command_factory at 0x7e9c43a59480>)\u001b[0m\n","> \u001b[1mINFO    Dataset: mistral-ty-cefr (lm_training)\n","Train data: ['./train.csv']\n","Valid data: []\n","Column mapping: {'text': 'text', 'rejected_text': 'rejected', 'prompt': 'prompt'}\n","\u001b[0m\n","\rSaving the dataset (0/1 shards):   0% 0/570 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 570/570 [00:00<00:00, 151476.48 examples/s]\rSaving the dataset (1/1 shards): 100% 570/570 [00:00<00:00, 144003.93 examples/s]\n","\rSaving the dataset (0/1 shards):   0% 0/570 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 570/570 [00:00<00:00, 134933.59 examples/s]\rSaving the dataset (1/1 shards): 100% 570/570 [00:00<00:00, 128500.58 examples/s]\n","> \u001b[1mINFO    Starting local training...\u001b[0m\n","> \u001b[1mINFO    {\"model\":\"filipealmeida/Mistral-7B-Instruct-v0.1-sharded\",\"project_name\":\"mistral-ty-cefr\",\"data_path\":\"mistral-ty-cefr/autotrain-data\",\"train_split\":\"train\",\"valid_split\":null,\"add_eos_token\":false,\"block_size\":-1,\"model_max_length\":1024,\"padding\":null,\"trainer\":\"sft\",\"use_flash_attention_2\":false,\"log\":\"none\",\"disable_gradient_checkpointing\":false,\"logging_steps\":-1,\"evaluation_strategy\":\"epoch\",\"save_total_limit\":1,\"save_strategy\":\"epoch\",\"auto_find_batch_size\":false,\"mixed_precision\":null,\"lr\":0.0002,\"epochs\":3,\"batch_size\":12,\"warmup_ratio\":0.1,\"gradient_accumulation\":1,\"optimizer\":\"adamw_torch\",\"scheduler\":\"linear\",\"weight_decay\":0.0,\"max_grad_norm\":1.0,\"seed\":42,\"apply_chat_template\":false,\"quantization\":null,\"target_modules\":\"q_proj,v_proj\",\"merge_adapter\":false,\"peft\":true,\"lora_r\":16,\"lora_alpha\":32,\"lora_dropout\":0.05,\"model_ref\":null,\"dpo_beta\":0.1,\"prompt_text_column\":\"autotrain_prompt\",\"text_column\":\"autotrain_text\",\"rejected_text_column\":\"autotrain_rejected_text\",\"push_to_hub\":true,\"repo_id\":\"auroresearch/mistral-ty-cefr\",\"username\":null,\"token\":\"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\"}\u001b[0m\n","> \u001b[1mINFO    ['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'mistral-ty-cefr/training_params.json']\u001b[0m\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-02-20 08:15:59\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n","\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-02-20 08:15:59\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mTrain data: Dataset({\n","    features: ['autotrain_text'],\n","    num_rows: 570\n","})\u001b[0m\n","\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-02-20 08:15:59\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mValid data: None\u001b[0m\n","tokenizer_config.json: 100% 1.47k/1.47k [00:00<00:00, 7.68MB/s]\n","tokenizer.model: 100% 493k/493k [00:00<00:00, 16.6MB/s]\n","tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 12.7MB/s]\n","special_tokens_map.json: 100% 72.0/72.0 [00:00<00:00, 336kB/s]\n","config.json: 100% 665/665 [00:00<00:00, 3.10MB/s]\n","pytorch_model.bin.index.json: 100% 23.9k/23.9k [00:00<00:00, 84.6MB/s]\n","Downloading shards:   0% 0/8 [00:00<?, ?it/s]\n","pytorch_model-00001-of-00008.bin:   0% 0.00/1.89G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:   1% 21.0M/1.89G [00:00<00:12, 152MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:   2% 41.9M/1.89G [00:00<00:11, 167MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:   4% 73.4M/1.89G [00:00<00:08, 217MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:   6% 105M/1.89G [00:00<00:07, 245MB/s] \u001b[A\n","pytorch_model-00001-of-00008.bin:   7% 136M/1.89G [00:00<00:07, 245MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:   9% 168M/1.89G [00:00<00:07, 241MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  11% 199M/1.89G [00:00<00:07, 236MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  12% 231M/1.89G [00:01<00:07, 231MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  14% 262M/1.89G [00:01<00:06, 237MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  16% 294M/1.89G [00:01<00:06, 249MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  17% 325M/1.89G [00:01<00:06, 257MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  19% 357M/1.89G [00:01<00:05, 266MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  21% 388M/1.89G [00:01<00:06, 234MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  22% 419M/1.89G [00:01<00:06, 237MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  24% 451M/1.89G [00:01<00:06, 239MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  26% 482M/1.89G [00:02<00:05, 239MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  27% 514M/1.89G [00:02<00:05, 241MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  29% 545M/1.89G [00:02<00:05, 245MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  31% 577M/1.89G [00:02<00:05, 248MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  32% 608M/1.89G [00:02<00:05, 246MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  34% 640M/1.89G [00:02<00:05, 249MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  36% 671M/1.89G [00:02<00:04, 255MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  37% 703M/1.89G [00:02<00:04, 255MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  39% 734M/1.89G [00:03<00:04, 252MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  41% 765M/1.89G [00:03<00:04, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  42% 797M/1.89G [00:03<00:04, 255MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  44% 828M/1.89G [00:03<00:04, 254MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  46% 860M/1.89G [00:03<00:04, 257MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  47% 891M/1.89G [00:03<00:03, 253MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  49% 923M/1.89G [00:03<00:03, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  50% 954M/1.89G [00:03<00:03, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  52% 986M/1.89G [00:04<00:03, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  54% 1.02G/1.89G [00:04<00:03, 254MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  55% 1.05G/1.89G [00:04<00:03, 251MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  57% 1.08G/1.89G [00:04<00:03, 249MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  59% 1.11G/1.89G [00:04<00:03, 249MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  60% 1.14G/1.89G [00:04<00:02, 252MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  62% 1.17G/1.89G [00:04<00:02, 252MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  64% 1.21G/1.89G [00:04<00:02, 251MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  65% 1.24G/1.89G [00:05<00:02, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  67% 1.27G/1.89G [00:05<00:02, 249MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  69% 1.30G/1.89G [00:05<00:02, 247MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  70% 1.33G/1.89G [00:05<00:02, 248MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  72% 1.36G/1.89G [00:05<00:02, 252MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  74% 1.39G/1.89G [00:05<00:01, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  75% 1.43G/1.89G [00:05<00:01, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  77% 1.46G/1.89G [00:05<00:01, 251MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  79% 1.49G/1.89G [00:06<00:01, 248MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  80% 1.52G/1.89G [00:06<00:01, 250MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  82% 1.55G/1.89G [00:06<00:01, 244MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  84% 1.58G/1.89G [00:06<00:01, 239MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  85% 1.61G/1.89G [00:06<00:01, 235MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  87% 1.65G/1.89G [00:06<00:01, 226MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  89% 1.68G/1.89G [00:06<00:00, 232MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  90% 1.71G/1.89G [00:07<00:00, 225MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  92% 1.74G/1.89G [00:07<00:00, 209MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  94% 1.77G/1.89G [00:07<00:00, 202MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  95% 1.79G/1.89G [00:07<00:00, 202MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  96% 1.81G/1.89G [00:07<00:00, 197MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin:  98% 1.85G/1.89G [00:07<00:00, 207MB/s]\u001b[A\n","pytorch_model-00001-of-00008.bin: 100% 1.89G/1.89G [00:07<00:00, 239MB/s]\n","Downloading shards:  12% 1/8 [00:08<00:56,  8.03s/it]\n","pytorch_model-00002-of-00008.bin:   0% 0.00/1.95G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:   2% 31.5M/1.95G [00:00<00:07, 258MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:   3% 62.9M/1.95G [00:00<00:07, 258MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:   5% 94.4M/1.95G [00:00<00:08, 222MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:   6% 126M/1.95G [00:00<00:08, 208MB/s] \u001b[A\n","pytorch_model-00002-of-00008.bin:   8% 157M/1.95G [00:00<00:08, 204MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:   9% 178M/1.95G [00:03<01:00, 29.3MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  11% 210M/1.95G [00:03<00:40, 42.8MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  12% 241M/1.95G [00:03<00:28, 60.0MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  14% 273M/1.95G [00:03<00:21, 78.8MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  16% 304M/1.95G [00:03<00:16, 102MB/s] \u001b[A\n","pytorch_model-00002-of-00008.bin:  17% 336M/1.95G [00:03<00:13, 120MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  19% 367M/1.95G [00:04<00:11, 137MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  20% 398M/1.95G [00:04<00:09, 160MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  22% 430M/1.95G [00:04<00:08, 179MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  24% 461M/1.95G [00:04<00:07, 195MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  25% 493M/1.95G [00:04<00:07, 203MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  27% 524M/1.95G [00:04<00:07, 201MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  29% 556M/1.95G [00:04<00:06, 206MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  30% 587M/1.95G [00:04<00:06, 217MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  32% 619M/1.95G [00:05<00:06, 198MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  33% 650M/1.95G [00:05<00:06, 197MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  34% 671M/1.95G [00:05<00:06, 196MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  36% 692M/1.95G [00:05<00:06, 197MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  37% 713M/1.95G [00:07<00:33, 36.4MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  38% 744M/1.95G [00:07<00:22, 52.8MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  40% 776M/1.95G [00:07<00:16, 72.5MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  41% 807M/1.95G [00:07<00:12, 94.1MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  43% 839M/1.95G [00:07<00:09, 116MB/s] \u001b[A\n","pytorch_model-00002-of-00008.bin:  45% 870M/1.95G [00:08<00:07, 135MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  46% 902M/1.95G [00:08<00:06, 156MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  48% 933M/1.95G [00:08<00:05, 175MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  50% 965M/1.95G [00:08<00:05, 192MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  51% 996M/1.95G [00:08<00:04, 205MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  53% 1.03G/1.95G [00:08<00:04, 211MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  54% 1.06G/1.95G [00:08<00:04, 216MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  56% 1.09G/1.95G [00:09<00:03, 229MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  58% 1.12G/1.95G [00:09<00:03, 235MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  59% 1.15G/1.95G [00:09<00:03, 237MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  61% 1.18G/1.95G [00:09<00:03, 236MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  62% 1.22G/1.95G [00:09<00:03, 243MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  64% 1.25G/1.95G [00:09<00:02, 246MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  66% 1.28G/1.95G [00:09<00:02, 237MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  67% 1.31G/1.95G [00:09<00:02, 241MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  69% 1.34G/1.95G [00:10<00:02, 246MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  71% 1.37G/1.95G [00:10<00:02, 246MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  72% 1.41G/1.95G [00:10<00:02, 250MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  74% 1.44G/1.95G [00:10<00:02, 252MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  75% 1.47G/1.95G [00:10<00:01, 251MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  77% 1.50G/1.95G [00:10<00:01, 250MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  79% 1.53G/1.95G [00:10<00:01, 254MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  80% 1.56G/1.95G [00:10<00:01, 251MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  82% 1.59G/1.95G [00:11<00:01, 249MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  84% 1.63G/1.95G [00:11<00:01, 245MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  85% 1.66G/1.95G [00:11<00:01, 241MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  87% 1.69G/1.95G [00:11<00:01, 233MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  88% 1.72G/1.95G [00:11<00:00, 239MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  90% 1.75G/1.95G [00:11<00:00, 241MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  92% 1.78G/1.95G [00:11<00:00, 236MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  93% 1.81G/1.95G [00:12<00:00, 215MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  95% 1.85G/1.95G [00:12<00:00, 205MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  96% 1.87G/1.95G [00:12<00:00, 196MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  97% 1.89G/1.95G [00:12<00:00, 174MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin:  99% 1.92G/1.95G [00:12<00:00, 196MB/s]\u001b[A\n","pytorch_model-00002-of-00008.bin: 100% 1.95G/1.95G [00:12<00:00, 151MB/s]\n","Downloading shards:  25% 2/8 [00:21<01:05, 10.97s/it]\n","pytorch_model-00003-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:   1% 10.5M/1.98G [00:00<00:47, 41.4MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:   1% 21.0M/1.98G [00:00<00:30, 63.8MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:   2% 41.9M/1.98G [00:00<00:20, 96.6MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:   3% 62.9M/1.98G [00:00<00:16, 113MB/s] \u001b[A\n","pytorch_model-00003-of-00008.bin:   4% 83.9M/1.98G [00:00<00:14, 133MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:   5% 105M/1.98G [00:00<00:12, 145MB/s] \u001b[A\n","pytorch_model-00003-of-00008.bin:   6% 126M/1.98G [00:01<00:11, 157MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:   7% 147M/1.98G [00:01<00:11, 163MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:   9% 178M/1.98G [00:01<00:09, 189MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  10% 199M/1.98G [00:01<00:09, 194MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  11% 220M/1.98G [00:01<00:09, 191MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  13% 252M/1.98G [00:01<00:08, 196MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  14% 273M/1.98G [00:01<00:08, 198MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  15% 294M/1.98G [00:01<00:10, 164MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  16% 315M/1.98G [00:02<00:09, 174MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  17% 336M/1.98G [00:03<00:38, 43.3MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  18% 357M/1.98G [00:03<00:28, 56.2MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  20% 388M/1.98G [00:03<00:20, 79.0MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  21% 419M/1.98G [00:03<00:15, 100MB/s] \u001b[A\n","pytorch_model-00003-of-00008.bin:  22% 440M/1.98G [00:03<00:14, 110MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  24% 472M/1.98G [00:04<00:11, 134MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  25% 503M/1.98G [00:04<00:09, 153MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  27% 535M/1.98G [00:04<00:10, 142MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  29% 566M/1.98G [00:04<00:09, 155MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  30% 587M/1.98G [00:04<00:08, 164MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  31% 608M/1.98G [00:04<00:08, 157MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  32% 629M/1.98G [00:05<00:08, 157MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  33% 650M/1.98G [00:05<00:08, 161MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  34% 682M/1.98G [00:05<00:07, 182MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  35% 703M/1.98G [00:05<00:06, 184MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  37% 734M/1.98G [00:05<00:06, 196MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  39% 765M/1.98G [00:05<00:05, 211MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  40% 797M/1.98G [00:05<00:05, 214MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  42% 828M/1.98G [00:05<00:05, 213MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  43% 860M/1.98G [00:06<00:05, 198MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  45% 891M/1.98G [00:06<00:05, 203MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  47% 923M/1.98G [00:06<00:05, 205MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  48% 944M/1.98G [00:06<00:05, 194MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  49% 965M/1.98G [00:06<00:05, 197MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  50% 996M/1.98G [00:06<00:04, 207MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  52% 1.03G/1.98G [00:06<00:04, 216MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  53% 1.06G/1.98G [00:07<00:04, 213MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  55% 1.09G/1.98G [00:07<00:04, 211MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  57% 1.12G/1.98G [00:07<00:04, 207MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  58% 1.15G/1.98G [00:07<00:03, 210MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  60% 1.18G/1.98G [00:07<00:03, 208MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  61% 1.21G/1.98G [00:07<00:03, 203MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  62% 1.23G/1.98G [00:07<00:03, 202MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  64% 1.26G/1.98G [00:08<00:03, 206MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  65% 1.28G/1.98G [00:09<00:14, 48.3MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  66% 1.31G/1.98G [00:09<00:10, 65.6MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  67% 1.33G/1.98G [00:09<00:08, 74.5MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  68% 1.35G/1.98G [00:09<00:07, 86.4MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  70% 1.38G/1.98G [00:10<00:05, 110MB/s] \u001b[A\n","pytorch_model-00003-of-00008.bin:  71% 1.41G/1.98G [00:10<00:05, 111MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  72% 1.43G/1.98G [00:10<00:04, 126MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  73% 1.45G/1.98G [00:10<00:05, 101MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  74% 1.47G/1.98G [00:11<00:05, 87.2MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  75% 1.49G/1.98G [00:11<00:04, 101MB/s] \u001b[A\n","pytorch_model-00003-of-00008.bin:  76% 1.51G/1.98G [00:11<00:03, 119MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  77% 1.53G/1.98G [00:11<00:03, 120MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  78% 1.55G/1.98G [00:11<00:04, 93.4MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  79% 1.57G/1.98G [00:12<00:04, 84.7MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  80% 1.58G/1.98G [00:12<00:05, 78.0MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  81% 1.60G/1.98G [00:12<00:04, 89.7MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  82% 1.61G/1.98G [00:14<00:15, 23.6MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  82% 1.63G/1.98G [00:14<00:13, 26.0MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  83% 1.65G/1.98G [00:14<00:09, 37.0MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  84% 1.66G/1.98G [00:14<00:07, 40.6MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  84% 1.67G/1.98G [00:14<00:06, 46.6MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  85% 1.68G/1.98G [00:15<00:06, 48.9MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  86% 1.70G/1.98G [00:15<00:04, 64.8MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  86% 1.71G/1.98G [00:15<00:03, 70.4MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  87% 1.73G/1.98G [00:15<00:02, 94.2MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  89% 1.76G/1.98G [00:15<00:01, 127MB/s] \u001b[A\n","pytorch_model-00003-of-00008.bin:  91% 1.79G/1.98G [00:15<00:01, 149MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  92% 1.81G/1.98G [00:15<00:01, 161MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  93% 1.85G/1.98G [00:16<00:00, 177MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  95% 1.88G/1.98G [00:16<00:00, 189MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  96% 1.91G/1.98G [00:16<00:00, 191MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  97% 1.93G/1.98G [00:16<00:00, 195MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin:  99% 1.95G/1.98G [00:16<00:00, 194MB/s]\u001b[A\n","pytorch_model-00003-of-00008.bin: 100% 1.98G/1.98G [00:16<00:00, 118MB/s]\n","Downloading shards:  38% 3/8 [00:37<01:08, 13.67s/it]\n","pytorch_model-00004-of-00008.bin:   0% 0.00/1.95G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:   2% 31.5M/1.95G [00:00<00:07, 254MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:   3% 62.9M/1.95G [00:00<00:07, 261MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:   5% 94.4M/1.95G [00:00<00:07, 244MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:   6% 126M/1.95G [00:00<00:07, 238MB/s] \u001b[A\n","pytorch_model-00004-of-00008.bin:   8% 157M/1.95G [00:00<00:07, 238MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  10% 189M/1.95G [00:02<00:43, 40.1MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  11% 210M/1.95G [00:02<00:35, 48.9MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  12% 231M/1.95G [00:02<00:29, 58.7MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  13% 252M/1.95G [00:03<00:23, 70.6MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  15% 283M/1.95G [00:03<00:17, 94.3MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  16% 315M/1.95G [00:03<00:14, 115MB/s] \u001b[A\n","pytorch_model-00004-of-00008.bin:  17% 336M/1.95G [00:03<00:12, 128MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  19% 367M/1.95G [00:03<00:10, 152MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  20% 398M/1.95G [00:03<00:09, 169MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  22% 430M/1.95G [00:03<00:07, 190MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  24% 461M/1.95G [00:04<00:07, 205MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  25% 493M/1.95G [00:04<00:06, 218MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  27% 524M/1.95G [00:04<00:06, 219MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  29% 556M/1.95G [00:04<00:06, 230MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  30% 587M/1.95G [00:04<00:05, 236MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  32% 619M/1.95G [00:04<00:05, 245MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  33% 650M/1.95G [00:04<00:05, 239MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  35% 682M/1.95G [00:04<00:05, 244MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  37% 713M/1.95G [00:05<00:04, 248MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  38% 744M/1.95G [00:05<00:04, 247MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  40% 776M/1.95G [00:05<00:04, 253MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  41% 807M/1.95G [00:05<00:04, 253MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  43% 839M/1.95G [00:05<00:04, 252MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  45% 870M/1.95G [00:05<00:04, 251MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  46% 902M/1.95G [00:05<00:04, 254MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  48% 933M/1.95G [00:05<00:04, 252MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  50% 965M/1.95G [00:06<00:04, 243MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  51% 996M/1.95G [00:06<00:03, 247MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  53% 1.03G/1.95G [00:06<00:03, 252MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  54% 1.06G/1.95G [00:06<00:03, 248MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  56% 1.09G/1.95G [00:06<00:03, 238MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  58% 1.12G/1.95G [00:06<00:03, 224MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  59% 1.15G/1.95G [00:06<00:03, 228MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  61% 1.18G/1.95G [00:07<00:03, 224MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  62% 1.22G/1.95G [00:07<00:03, 200MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  64% 1.24G/1.95G [00:07<00:03, 201MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  65% 1.26G/1.95G [00:07<00:03, 199MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  66% 1.28G/1.95G [00:07<00:03, 195MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  67% 1.30G/1.95G [00:07<00:03, 187MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  68% 1.33G/1.95G [00:07<00:03, 201MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  70% 1.35G/1.95G [00:07<00:03, 178MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  71% 1.37G/1.95G [00:08<00:03, 174MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  72% 1.39G/1.95G [00:08<00:04, 118MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  73% 1.42G/1.95G [00:08<00:04, 131MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  74% 1.44G/1.95G [00:08<00:03, 137MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  75% 1.46G/1.95G [00:08<00:03, 145MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  77% 1.49G/1.95G [00:08<00:02, 167MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  78% 1.51G/1.95G [00:09<00:02, 170MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  79% 1.54G/1.95G [00:09<00:02, 191MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  81% 1.57G/1.95G [00:09<00:01, 197MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  82% 1.59G/1.95G [00:09<00:01, 182MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  83% 1.61G/1.95G [00:09<00:01, 176MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  84% 1.64G/1.95G [00:09<00:01, 180MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  86% 1.67G/1.95G [00:10<00:04, 67.6MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  87% 1.69G/1.95G [00:12<00:09, 28.1MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  88% 1.72G/1.95G [00:12<00:05, 41.2MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  90% 1.75G/1.95G [00:12<00:03, 57.9MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  91% 1.77G/1.95G [00:13<00:02, 69.1MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  92% 1.79G/1.95G [00:13<00:01, 79.2MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  93% 1.81G/1.95G [00:13<00:01, 92.0MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  94% 1.84G/1.95G [00:13<00:01, 108MB/s] \u001b[A\n","pytorch_model-00004-of-00008.bin:  95% 1.86G/1.95G [00:13<00:00, 120MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  96% 1.88G/1.95G [00:13<00:00, 135MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  98% 1.90G/1.95G [00:13<00:00, 148MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin:  99% 1.92G/1.95G [00:15<00:00, 37.7MB/s]\u001b[A\n","pytorch_model-00004-of-00008.bin: 100% 1.95G/1.95G [00:16<00:00, 119MB/s] \n","Downloading shards:  50% 4/8 [00:54<00:59, 14.77s/it]\n","pytorch_model-00005-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   1% 10.5M/1.98G [00:00<01:45, 18.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   1% 21.0M/1.98G [00:00<01:04, 30.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   2% 31.5M/1.98G [00:00<00:47, 41.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   2% 41.9M/1.98G [00:01<00:40, 47.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   3% 52.4M/1.98G [00:01<00:41, 47.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   3% 62.9M/1.98G [00:01<00:38, 49.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   4% 73.4M/1.98G [00:01<00:34, 54.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   4% 83.9M/1.98G [00:01<00:40, 46.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   5% 94.4M/1.98G [00:02<00:38, 49.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   5% 105M/1.98G [00:02<00:36, 51.7MB/s] \u001b[A\n","pytorch_model-00005-of-00008.bin:   6% 115M/1.98G [00:02<00:35, 52.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   6% 126M/1.98G [00:02<00:34, 53.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   7% 136M/1.98G [00:02<00:33, 54.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   7% 147M/1.98G [00:03<00:39, 46.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   8% 157M/1.98G [00:03<00:36, 49.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   8% 168M/1.98G [00:03<00:37, 48.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:   9% 178M/1.98G [00:03<00:33, 53.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  10% 189M/1.98G [00:03<00:32, 54.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  10% 199M/1.98G [00:04<00:34, 52.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  11% 210M/1.98G [00:04<00:36, 48.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  11% 220M/1.98G [00:04<00:35, 50.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  12% 231M/1.98G [00:04<00:35, 49.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  12% 241M/1.98G [00:05<00:35, 49.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  13% 252M/1.98G [00:05<00:33, 52.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  13% 262M/1.98G [00:05<00:33, 50.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  14% 273M/1.98G [00:05<00:33, 51.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  14% 283M/1.98G [00:05<00:33, 50.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  15% 294M/1.98G [00:06<00:42, 40.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  15% 304M/1.98G [00:06<00:42, 39.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  16% 315M/1.98G [00:06<00:36, 45.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  16% 325M/1.98G [00:06<00:39, 41.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  17% 336M/1.98G [00:07<00:34, 47.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  17% 346M/1.98G [00:07<00:38, 42.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  18% 357M/1.98G [00:07<00:36, 44.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  19% 367M/1.98G [00:07<00:31, 50.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  19% 377M/1.98G [00:07<00:30, 52.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  20% 388M/1.98G [00:08<00:27, 57.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  20% 398M/1.98G [00:08<00:34, 46.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  21% 409M/1.98G [00:08<00:34, 46.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  21% 419M/1.98G [00:08<00:38, 40.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  22% 430M/1.98G [00:09<00:35, 44.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  22% 440M/1.98G [00:09<00:41, 36.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  23% 451M/1.98G [00:09<00:38, 39.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  23% 461M/1.98G [00:09<00:34, 43.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  24% 472M/1.98G [00:10<00:32, 47.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  24% 482M/1.98G [00:10<00:29, 51.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  25% 493M/1.98G [00:10<00:27, 53.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  25% 503M/1.98G [00:10<00:37, 39.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  26% 514M/1.98G [00:11<00:44, 32.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  26% 524M/1.98G [00:11<00:42, 34.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  27% 535M/1.98G [00:11<00:37, 38.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  28% 545M/1.98G [00:12<00:37, 37.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  28% 556M/1.98G [00:12<00:34, 41.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  29% 566M/1.98G [00:12<00:42, 33.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  30% 587M/1.98G [00:12<00:26, 51.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  30% 598M/1.98G [00:13<00:28, 48.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  31% 608M/1.98G [00:13<00:33, 40.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  31% 619M/1.98G [00:13<00:31, 43.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  32% 629M/1.98G [00:13<00:29, 45.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  32% 640M/1.98G [00:14<00:28, 47.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  33% 650M/1.98G [00:14<00:27, 48.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  33% 661M/1.98G [00:14<00:28, 46.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  34% 671M/1.98G [00:14<00:25, 51.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  34% 682M/1.98G [00:15<00:34, 37.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  35% 692M/1.98G [00:15<00:30, 41.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  35% 703M/1.98G [00:15<00:27, 47.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  36% 713M/1.98G [00:15<00:25, 49.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  37% 724M/1.98G [00:15<00:26, 46.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  37% 734M/1.98G [00:16<00:25, 49.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  38% 744M/1.98G [00:16<00:25, 48.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  38% 755M/1.98G [00:16<00:27, 44.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  39% 765M/1.98G [00:16<00:25, 47.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  39% 776M/1.98G [00:16<00:22, 53.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  40% 786M/1.98G [00:17<00:23, 50.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  40% 797M/1.98G [00:17<00:21, 55.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  41% 807M/1.98G [00:17<00:23, 50.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  41% 818M/1.98G [00:17<00:22, 52.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  42% 828M/1.98G [00:18<00:22, 50.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  42% 839M/1.98G [00:18<00:26, 43.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  43% 849M/1.98G [00:18<00:24, 46.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  43% 860M/1.98G [00:18<00:23, 48.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  44% 870M/1.98G [00:18<00:20, 53.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  44% 881M/1.98G [00:19<00:29, 37.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  45% 891M/1.98G [00:19<00:26, 41.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  46% 902M/1.98G [00:19<00:31, 34.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  46% 912M/1.98G [00:20<00:32, 33.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  47% 923M/1.98G [00:20<00:26, 39.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  47% 933M/1.98G [00:20<00:26, 39.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  48% 944M/1.98G [00:21<00:26, 38.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  48% 954M/1.98G [00:21<00:28, 35.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  49% 965M/1.98G [00:21<00:27, 36.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  49% 975M/1.98G [00:21<00:23, 42.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  50% 986M/1.98G [00:21<00:21, 46.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  50% 996M/1.98G [00:22<00:21, 45.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  51% 1.01G/1.98G [00:22<00:19, 50.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  51% 1.02G/1.98G [00:22<00:27, 35.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  52% 1.03G/1.98G [00:23<00:28, 32.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  52% 1.04G/1.98G [00:23<00:26, 35.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  53% 1.05G/1.98G [00:23<00:24, 37.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  53% 1.06G/1.98G [00:23<00:24, 37.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  54% 1.07G/1.98G [00:24<00:21, 41.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  55% 1.08G/1.98G [00:24<00:18, 47.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  55% 1.09G/1.98G [00:24<00:18, 47.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  56% 1.10G/1.98G [00:24<00:18, 48.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  56% 1.11G/1.98G [00:25<00:24, 36.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  57% 1.12G/1.98G [00:25<00:22, 38.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  57% 1.13G/1.98G [00:25<00:20, 42.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  58% 1.14G/1.98G [00:26<00:24, 34.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  58% 1.15G/1.98G [00:26<00:22, 36.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  59% 1.16G/1.98G [00:26<00:20, 40.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  59% 1.17G/1.98G [00:26<00:19, 40.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  60% 1.18G/1.98G [00:26<00:17, 44.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  60% 1.20G/1.98G [00:27<00:17, 45.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  61% 1.21G/1.98G [00:27<00:16, 47.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  61% 1.22G/1.98G [00:27<00:15, 50.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  62% 1.23G/1.98G [00:27<00:13, 55.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  62% 1.24G/1.98G [00:27<00:15, 48.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  63% 1.25G/1.98G [00:28<00:14, 50.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  64% 1.26G/1.98G [00:28<00:16, 44.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  64% 1.27G/1.98G [00:28<00:13, 50.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  65% 1.28G/1.98G [00:28<00:12, 55.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  65% 1.29G/1.98G [00:28<00:13, 50.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  66% 1.30G/1.98G [00:29<00:13, 52.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  66% 1.31G/1.98G [00:29<00:11, 57.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  67% 1.32G/1.98G [00:29<00:11, 56.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  67% 1.33G/1.98G [00:29<00:12, 50.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  68% 1.34G/1.98G [00:29<00:12, 52.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  68% 1.35G/1.98G [00:30<00:14, 42.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  69% 1.36G/1.98G [00:30<00:17, 35.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  69% 1.37G/1.98G [00:30<00:14, 40.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  70% 1.38G/1.98G [00:31<00:14, 39.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  70% 1.39G/1.98G [00:31<00:13, 44.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  71% 1.41G/1.98G [00:31<00:12, 46.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  72% 1.42G/1.98G [00:31<00:11, 49.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  72% 1.43G/1.98G [00:32<00:13, 42.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  73% 1.44G/1.98G [00:32<00:11, 46.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  73% 1.45G/1.98G [00:32<00:10, 50.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  74% 1.46G/1.98G [00:32<00:13, 39.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  74% 1.47G/1.98G [00:33<00:12, 39.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  75% 1.48G/1.98G [00:33<00:11, 42.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  75% 1.49G/1.98G [00:33<00:13, 36.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  76% 1.50G/1.98G [00:33<00:11, 41.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  76% 1.51G/1.98G [00:34<00:11, 40.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  77% 1.52G/1.98G [00:34<00:10, 43.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  77% 1.53G/1.98G [00:34<00:09, 45.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  78% 1.54G/1.98G [00:34<00:10, 40.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  78% 1.55G/1.98G [00:35<00:13, 32.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  79% 1.56G/1.98G [00:35<00:12, 34.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  79% 1.57G/1.98G [00:35<00:10, 38.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  80% 1.58G/1.98G [00:36<00:11, 35.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  81% 1.59G/1.98G [00:36<00:10, 38.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  81% 1.60G/1.98G [00:36<00:09, 38.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  82% 1.61G/1.98G [00:36<00:08, 42.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  82% 1.63G/1.98G [00:37<00:08, 42.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  83% 1.64G/1.98G [00:37<00:09, 37.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  83% 1.65G/1.98G [00:37<00:08, 41.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  84% 1.66G/1.98G [00:37<00:08, 38.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  84% 1.67G/1.98G [00:38<00:08, 34.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  85% 1.68G/1.98G [00:38<00:07, 40.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  85% 1.69G/1.98G [00:38<00:07, 38.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  86% 1.70G/1.98G [00:38<00:06, 42.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  86% 1.71G/1.98G [00:39<00:05, 46.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  87% 1.72G/1.98G [00:39<00:06, 41.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  87% 1.73G/1.98G [00:39<00:06, 40.0MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  88% 1.74G/1.98G [00:39<00:05, 43.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  88% 1.75G/1.98G [00:40<00:05, 38.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  89% 1.76G/1.98G [00:40<00:06, 33.7MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  90% 1.77G/1.98G [00:40<00:05, 38.2MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  90% 1.78G/1.98G [00:41<00:05, 38.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  91% 1.79G/1.98G [00:41<00:05, 36.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  91% 1.80G/1.98G [00:41<00:04, 42.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  92% 1.81G/1.98G [00:41<00:03, 42.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  92% 1.82G/1.98G [00:42<00:03, 45.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  93% 1.84G/1.98G [00:42<00:03, 47.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  93% 1.85G/1.98G [00:42<00:02, 52.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  94% 1.86G/1.98G [00:42<00:02, 52.3MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  94% 1.87G/1.98G [00:42<00:02, 49.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  95% 1.88G/1.98G [00:43<00:02, 46.9MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  95% 1.89G/1.98G [00:43<00:01, 51.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  96% 1.90G/1.98G [00:43<00:02, 40.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  96% 1.91G/1.98G [00:43<00:02, 35.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  97% 1.92G/1.98G [00:44<00:01, 41.5MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  97% 1.93G/1.98G [00:44<00:01, 45.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  98% 1.94G/1.98G [00:44<00:00, 47.4MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  99% 1.95G/1.98G [00:44<00:00, 50.1MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin:  99% 1.96G/1.98G [00:45<00:00, 40.8MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin: 100% 1.97G/1.98G [00:45<00:00, 46.6MB/s]\u001b[A\n","pytorch_model-00005-of-00008.bin: 100% 1.98G/1.98G [00:45<00:00, 43.7MB/s]\n","Downloading shards:  62% 5/8 [01:40<01:18, 26.02s/it]\n","pytorch_model-00006-of-00008.bin:   0% 0.00/1.95G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:   2% 31.5M/1.95G [00:00<00:07, 260MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:   3% 62.9M/1.95G [00:00<00:08, 225MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:   5% 94.4M/1.95G [00:00<00:08, 225MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:   6% 126M/1.95G [00:01<00:19, 94.9MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:   8% 157M/1.95G [00:01<00:14, 120MB/s] \u001b[A\n","pytorch_model-00006-of-00008.bin:  10% 189M/1.95G [00:01<00:11, 147MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  11% 220M/1.95G [00:01<00:09, 174MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  13% 252M/1.95G [00:01<00:08, 189MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  15% 283M/1.95G [00:01<00:09, 168MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  16% 304M/1.95G [00:01<00:09, 171MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  17% 336M/1.95G [00:02<00:08, 187MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  18% 357M/1.95G [00:02<00:08, 188MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  20% 388M/1.95G [00:02<00:07, 198MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  22% 419M/1.95G [00:02<00:07, 211MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  23% 451M/1.95G [00:02<00:07, 211MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  25% 482M/1.95G [00:02<00:06, 213MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  26% 514M/1.95G [00:02<00:06, 223MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  28% 545M/1.95G [00:02<00:06, 233MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  30% 577M/1.95G [00:03<00:05, 237MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  31% 608M/1.95G [00:03<00:05, 244MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  33% 640M/1.95G [00:03<00:05, 247MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  34% 671M/1.95G [00:03<00:05, 250MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  36% 703M/1.95G [00:03<00:04, 252MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  38% 734M/1.95G [00:03<00:04, 250MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  39% 765M/1.95G [00:03<00:04, 252MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  41% 797M/1.95G [00:03<00:04, 252MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  43% 828M/1.95G [00:04<00:04, 248MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  44% 860M/1.95G [00:04<00:04, 250MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  46% 891M/1.95G [00:04<00:04, 244MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  47% 923M/1.95G [00:04<00:04, 249MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  49% 954M/1.95G [00:04<00:04, 246MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  51% 986M/1.95G [00:04<00:03, 254MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  52% 1.02G/1.95G [00:04<00:03, 244MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  54% 1.05G/1.95G [00:04<00:03, 248MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  55% 1.08G/1.95G [00:05<00:03, 253MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  57% 1.11G/1.95G [00:05<00:03, 249MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  59% 1.14G/1.95G [00:05<00:03, 254MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  60% 1.17G/1.95G [00:05<00:03, 250MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  62% 1.21G/1.95G [00:05<00:02, 250MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  64% 1.24G/1.95G [00:05<00:02, 256MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  65% 1.27G/1.95G [00:05<00:02, 253MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  67% 1.30G/1.95G [00:05<00:02, 232MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  68% 1.33G/1.95G [00:06<00:02, 229MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  70% 1.36G/1.95G [00:06<00:02, 233MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  72% 1.39G/1.95G [00:06<00:02, 237MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  73% 1.43G/1.95G [00:06<00:02, 227MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  75% 1.46G/1.95G [00:06<00:02, 214MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  77% 1.49G/1.95G [00:06<00:02, 199MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  78% 1.51G/1.95G [00:07<00:02, 194MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  79% 1.54G/1.95G [00:07<00:02, 199MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  81% 1.57G/1.95G [00:07<00:01, 208MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  82% 1.60G/1.95G [00:07<00:01, 216MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  84% 1.64G/1.95G [00:07<00:01, 205MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  85% 1.66G/1.95G [00:07<00:01, 194MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  86% 1.68G/1.95G [00:07<00:01, 179MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  87% 1.70G/1.95G [00:07<00:01, 179MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  88% 1.72G/1.95G [00:08<00:01, 182MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  89% 1.74G/1.95G [00:11<00:08, 23.2MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  91% 1.77G/1.95G [00:11<00:04, 35.3MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  92% 1.79G/1.95G [00:11<00:03, 44.4MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  93% 1.81G/1.95G [00:11<00:02, 54.6MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  94% 1.84G/1.95G [00:11<00:01, 68.0MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  95% 1.86G/1.95G [00:11<00:01, 84.3MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  96% 1.88G/1.95G [00:11<00:00, 101MB/s] \u001b[A\n","pytorch_model-00006-of-00008.bin:  98% 1.90G/1.95G [00:11<00:00, 117MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin:  99% 1.92G/1.95G [00:11<00:00, 133MB/s]\u001b[A\n","pytorch_model-00006-of-00008.bin: 100% 1.95G/1.95G [00:12<00:00, 160MB/s]\n","Downloading shards:  75% 6/8 [01:52<00:42, 21.34s/it]\n","pytorch_model-00007-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:   1% 10.5M/1.98G [00:00<00:47, 41.3MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:   1% 21.0M/1.98G [00:00<00:32, 59.8MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:   2% 41.9M/1.98G [00:00<00:21, 89.2MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:   3% 62.9M/1.98G [00:00<00:17, 109MB/s] \u001b[A\n","pytorch_model-00007-of-00008.bin:   4% 83.9M/1.98G [00:00<00:14, 134MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:   5% 105M/1.98G [00:00<00:12, 151MB/s] \u001b[A\n","pytorch_model-00007-of-00008.bin:   7% 136M/1.98G [00:01<00:10, 173MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:   8% 157M/1.98G [00:01<00:10, 179MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  10% 189M/1.98G [00:01<00:09, 197MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  11% 220M/1.98G [00:01<00:08, 202MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  13% 252M/1.98G [00:01<00:08, 206MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  14% 273M/1.98G [00:01<00:08, 203MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  15% 304M/1.98G [00:01<00:08, 205MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  17% 336M/1.98G [00:01<00:07, 213MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  19% 367M/1.98G [00:02<00:07, 211MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  20% 398M/1.98G [00:02<00:07, 209MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  21% 419M/1.98G [00:02<00:07, 207MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  22% 440M/1.98G [00:02<00:07, 207MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  24% 472M/1.98G [00:02<00:07, 210MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  25% 493M/1.98G [00:02<00:07, 210MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  26% 514M/1.98G [00:03<00:12, 115MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  28% 545M/1.98G [00:03<00:09, 146MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  29% 566M/1.98G [00:03<00:09, 146MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  30% 587M/1.98G [00:03<00:09, 148MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  31% 608M/1.98G [00:03<00:08, 157MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  32% 629M/1.98G [00:03<00:08, 167MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  33% 661M/1.98G [00:03<00:07, 174MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  34% 682M/1.98G [00:04<00:07, 179MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  36% 713M/1.98G [00:04<00:06, 192MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  38% 744M/1.98G [00:04<00:06, 203MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  39% 776M/1.98G [00:04<00:05, 210MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  41% 807M/1.98G [00:04<00:05, 207MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  42% 828M/1.98G [00:04<00:05, 207MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  43% 860M/1.98G [00:04<00:05, 209MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  44% 881M/1.98G [00:04<00:05, 209MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  46% 902M/1.98G [00:05<00:05, 207MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  47% 933M/1.98G [00:05<00:05, 208MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  48% 954M/1.98G [00:05<00:04, 208MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  50% 986M/1.98G [00:05<00:04, 210MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  51% 1.01G/1.98G [00:05<00:04, 208MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  52% 1.04G/1.98G [00:05<00:04, 207MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  53% 1.06G/1.98G [00:05<00:04, 202MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  55% 1.09G/1.98G [00:05<00:04, 211MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  57% 1.12G/1.98G [00:06<00:04, 211MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  58% 1.15G/1.98G [00:06<00:03, 207MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  59% 1.17G/1.98G [00:06<00:03, 206MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  60% 1.20G/1.98G [00:06<00:04, 196MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  61% 1.22G/1.98G [00:06<00:03, 194MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  62% 1.24G/1.98G [00:06<00:03, 198MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  64% 1.26G/1.98G [00:06<00:03, 200MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  65% 1.28G/1.98G [00:08<00:21, 32.7MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  66% 1.31G/1.98G [00:08<00:13, 49.0MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  67% 1.33G/1.98G [00:09<00:11, 57.6MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  68% 1.35G/1.98G [00:09<00:08, 71.2MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  69% 1.37G/1.98G [00:09<00:06, 86.8MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  71% 1.41G/1.98G [00:09<00:05, 114MB/s] \u001b[A\n","pytorch_model-00007-of-00008.bin:  72% 1.43G/1.98G [00:09<00:04, 129MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  73% 1.45G/1.98G [00:09<00:03, 139MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  75% 1.48G/1.98G [00:09<00:03, 161MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  76% 1.50G/1.98G [00:13<00:23, 20.6MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  77% 1.52G/1.98G [00:13<00:19, 24.0MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  78% 1.54G/1.98G [00:14<00:14, 29.4MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  78% 1.55G/1.98G [00:14<00:13, 32.6MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  79% 1.57G/1.98G [00:14<00:09, 44.5MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  81% 1.60G/1.98G [00:14<00:06, 59.9MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  82% 1.63G/1.98G [00:14<00:05, 68.7MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  83% 1.65G/1.98G [00:14<00:03, 84.3MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  85% 1.68G/1.98G [00:15<00:02, 109MB/s] \u001b[A\n","pytorch_model-00007-of-00008.bin:  86% 1.71G/1.98G [00:15<00:02, 132MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  88% 1.74G/1.98G [00:15<00:01, 151MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  90% 1.77G/1.98G [00:15<00:01, 167MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  91% 1.79G/1.98G [00:15<00:01, 175MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  92% 1.81G/1.98G [00:15<00:00, 174MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  93% 1.84G/1.98G [00:15<00:00, 174MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  94% 1.86G/1.98G [00:15<00:00, 178MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  95% 1.88G/1.98G [00:16<00:00, 180MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  96% 1.90G/1.98G [00:16<00:00, 183MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  97% 1.93G/1.98G [00:16<00:00, 193MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin:  99% 1.95G/1.98G [00:16<00:00, 197MB/s]\u001b[A\n","pytorch_model-00007-of-00008.bin: 100% 1.98G/1.98G [00:18<00:00, 105MB/s] \n","Downloading shards:  88% 7/8 [02:11<00:20, 20.56s/it]\n","pytorch_model-00008-of-00008.bin:   0% 0.00/816M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:   1% 10.5M/816M [00:00<00:10, 77.8MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:   3% 21.0M/816M [00:00<00:09, 84.7MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:   5% 41.9M/816M [00:00<00:06, 113MB/s] \u001b[A\n","pytorch_model-00008-of-00008.bin:   8% 62.9M/816M [00:00<00:05, 133MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  10% 83.9M/816M [00:00<00:04, 154MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  14% 115M/816M [00:00<00:04, 170MB/s] \u001b[A\n","pytorch_model-00008-of-00008.bin:  17% 136M/816M [00:00<00:03, 171MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  19% 157M/816M [00:01<00:03, 174MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  22% 178M/816M [00:01<00:03, 174MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  24% 199M/816M [00:01<00:03, 181MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  27% 220M/816M [00:01<00:03, 183MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  31% 252M/816M [00:01<00:02, 198MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  35% 283M/816M [00:01<00:02, 201MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  37% 304M/816M [00:01<00:02, 190MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  40% 325M/816M [00:01<00:02, 188MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  44% 357M/816M [00:02<00:02, 202MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  48% 388M/816M [00:02<00:02, 210MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  51% 419M/816M [00:02<00:01, 211MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  55% 451M/816M [00:02<00:01, 200MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  59% 482M/816M [00:02<00:01, 208MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  63% 514M/816M [00:02<00:01, 216MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  67% 545M/816M [00:04<00:06, 43.1MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  71% 577M/816M [00:04<00:04, 57.2MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  73% 598M/816M [00:05<00:03, 64.6MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  76% 619M/816M [00:05<00:02, 75.7MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  78% 640M/816M [00:05<00:01, 90.6MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  82% 671M/816M [00:05<00:01, 113MB/s] \u001b[A\n","pytorch_model-00008-of-00008.bin:  85% 692M/816M [00:05<00:00, 128MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  87% 713M/816M [00:05<00:00, 139MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  91% 744M/816M [00:05<00:00, 164MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  94% 765M/816M [00:09<00:02, 19.0MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin:  96% 786M/816M [00:09<00:01, 25.1MB/s]\u001b[A\n","pytorch_model-00008-of-00008.bin: 100% 816M/816M [00:10<00:00, 80.3MB/s]\n","Downloading shards: 100% 8/8 [02:21<00:00, 17.74s/it]\n","Loading checkpoint shards:   0% 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","Loading checkpoint shards:  25% 2/8 [00:18<00:55,  9.26s/it]Traceback (most recent call last):\n","  File \"/usr/local/bin/accelerate\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n","    args.func(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1023, in launch_command\n","    simple_launcher(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 643, in simple_launcher\n","    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n","subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'autotrain.trainers.clm', '--training_config', 'mistral-ty-cefr/training_params.json']' died with <Signals.SIGKILL: 9>.\n"]}]},{"cell_type":"markdown","source":["## AutoTrain\n"],"metadata":{"id":"bfVjSp0rOiSs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"h13KDzbXs8S_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708408903245,"user_tz":-330,"elapsed":6873,"user":{"displayName":"Silvester J K","userId":"15370919993856427806"}},"outputId":"94b695f1-d5d4-4b81-b36a-a2c8b4127bd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["usage: autotrain <command> [<args>] llm [-h] [--text_column TEXT_COLUMN]\n","                                        [--rejected_text_column REJECTED_TEXT_COLUMN]\n","                                        [--prompt-text-column PROMPT_TEXT_COLUMN]\n","                                        [--model-ref MODEL_REF] [--warmup_ratio WARMUP_RATIO]\n","                                        [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n","                                        [--weight_decay WEIGHT_DECAY]\n","                                        [--max_grad_norm MAX_GRAD_NORM] [--add_eos_token]\n","                                        [--block_size BLOCK_SIZE] [--peft] [--lora_r LORA_R]\n","                                        [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]\n","                                        [--logging_steps LOGGING_STEPS]\n","                                        [--evaluation_strategy EVALUATION_STRATEGY]\n","                                        [--save_total_limit SAVE_TOTAL_LIMIT]\n","                                        [--save_strategy SAVE_STRATEGY] [--auto_find_batch_size]\n","                                        [--mixed-precision MIXED_PRECISION]\n","                                        [--quantization QUANTIZATION]\n","                                        [--model_max_length MODEL_MAX_LENGTH] [--trainer TRAINER]\n","                                        [--target_modules TARGET_MODULES] [--merge_adapter]\n","                                        [--use_flash_attention_2] [--dpo-beta DPO_BETA]\n","                                        [--apply_chat_template] [--padding PADDING] [--train]\n","                                        [--deploy] [--inference] [--username USERNAME]\n","                                        [--backend BACKEND] [--token TOKEN] [--repo-id REPO_ID]\n","                                        [--push-to-hub] --model MODEL --project-name PROJECT_NAME\n","                                        [--seed SEED] [--epochs EPOCHS]\n","                                        [--gradient-accumulation GRADIENT_ACCUMULATION]\n","                                        [--disable_gradient_checkpointing] [--lr LR] [--log LOG]\n","                                        [--data-path DATA_PATH] [--train-split TRAIN_SPLIT]\n","                                        [--valid-split VALID_SPLIT] [--batch-size BATCH_SIZE]\n","\n","✨ Run AutoTrain LLM\n","\n","options:\n","  -h, --help            show this help message and exit\n","  --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n","                        Text column to use\n","  --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n","                        Rejected text column to use\n","  --prompt-text-column PROMPT_TEXT_COLUMN, --prompt-text-column PROMPT_TEXT_COLUMN\n","                        Prompt text column to use\n","  --model-ref MODEL_REF\n","                        Reference model to use for DPO when not using PEFT\n","  --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n","                        Warmup proportion to use\n","  --optimizer OPTIMIZER\n","                        Optimizer to use\n","  --scheduler SCHEDULER\n","                        Scheduler to use\n","  --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n","                        Weight decay to use\n","  --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n","                        Max gradient norm to use\n","  --add_eos_token, --add-eos-token\n","                        Add EOS token to use\n","  --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n","                        Block size to use\n","  --peft, --use-peft    Use PEFT\n","  --lora_r LORA_R, --lora-r LORA_R\n","                        Lora r to use\n","  --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n","                        Lora alpha to use\n","  --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n","                        Lora dropout to use\n","  --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n","                        Logging steps to use\n","  --evaluation_strategy EVALUATION_STRATEGY, --evaluation-strategy EVALUATION_STRATEGY\n","                        Evaluation strategy to use\n","  --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n","                        Save total limit to use\n","  --save_strategy SAVE_STRATEGY, --save-strategy SAVE_STRATEGY\n","                        Save strategy to use\n","  --auto_find_batch_size, --auto-find-batch-size\n","                        Auto find batch size True/False\n","  --mixed-precision MIXED_PRECISION, --mixed-precision MIXED_PRECISION, --mp MIXED_PRECISION\n","                        fp16, bf16, or None\n","  --quantization QUANTIZATION, --quantization QUANTIZATION\n","                        int4, int8, or None\n","  --model_max_length MODEL_MAX_LENGTH, --max-len MODEL_MAX_LENGTH, --max-length MODEL_MAX_LENGTH\n","                        Model max length to use\n","  --trainer TRAINER     Trainer type to use\n","  --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n","                        Target modules to use\n","  --merge_adapter, --merge-adapter\n","                        Use this flag to merge PEFT adapter with the model\n","  --use_flash_attention_2, --use-flash-attention-2, --use-fa2\n","                        Use flash attention 2\n","  --dpo-beta DPO_BETA, --dpo-beta DPO_BETA\n","                        Beta for DPO trainer\n","  --apply_chat_template, --apply-chat-template\n","                        Apply chat template\n","  --padding PADDING, --padding PADDING\n","                        Padding side\n","  --train               Train the model\n","  --deploy              Deploy the model\n","  --inference           Run inference\n","  --username USERNAME   Hugging Face Hub Username\n","  --backend BACKEND     Backend to use: default or spaces. Spaces backend requires push_to_hub and\n","                        repo_id\n","  --token TOKEN         Hub token\n","  --repo-id REPO_ID     Hub repo id\n","  --push-to-hub         Push to hub\n","  --model MODEL         Model to use for training\n","  --project-name PROJECT_NAME\n","                        Output directory or repo id\n","  --seed SEED           Seed\n","  --epochs EPOCHS       Number of training epochs\n","  --gradient-accumulation GRADIENT_ACCUMULATION\n","                        Gradient accumulation steps\n","  --disable_gradient_checkpointing, --disable-gradient-checkpointing, --disable-gc\n","                        Disable gradient checkpointing\n","  --lr LR               Learning rate\n","  --log LOG             Use experiment tracking\n","  --data-path DATA_PATH\n","                        Train dataset to use\n","  --train-split TRAIN_SPLIT\n","                        Test dataset split to use\n","  --valid-split VALID_SPLIT\n","                        Validation dataset split to use\n","  --batch-size BATCH_SIZE, --train-batch-size BATCH_SIZE\n","                        Training batch size to use\n"]}],"source":["!autotrain llm -h"]},{"cell_type":"code","source":["!pip install -q safetensors"],"metadata":{"id":"3ePscSsU7NQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from peft import PeftModel\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","model_name = \"bn22/Mistral-7B-Instruct-v0.1-sharded\"\n","#adapters_name = \"1littlecoder/mistral-7b-mj-finetune\"\n","\n","device = \"cuda\" # the device to load the model onto\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","   # load_in_4bit=True,\n","    torch_dtype=torch.bfloat16,\n","    device_map='auto'\n",")\n","##model = PeftModel.from_pretrained(model, adapters_name)\n","#model = model.merge_and_unload()\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.bos_token_id = 1\n","\n","stop_token_ids = [0]\n","\n","print(f\"Successfully loaded the model {model_name} into memory\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519,"referenced_widgets":["a6597053837e49c5bfc6abdcb2cd5996","3f2935a997404d2bb2d08f0d7ffd2d60","03a783b50be74bf9a9e97547ad1e424b","e6c5ad3ed36b4125bb01f0acde059a5c","dbee9553b87f442daa0d3d64a95df804","3fbc4aece31546abbce9bbdcd352b2cd","6bf6a07df47149bfa8fb177032cf8342","5f6a790133da475292389cfd91987321","1e4dc568fa354c52a94fbbda37c11017","0444bccad4424d4eb66e8350e39ce8e3","ca0f440c19d44fbc8885ad55f2669944","947c1645128c4d80bb4baf508cd80a01","a9f287f8680945bebd452265a65f838c","bd83476c5ea84a09a8196dcaf8ba5a84","e62baa5a2fb6449cb7c5cf696b2b2e08","fdc2bf14c2de4c66b786091afd510eea","3709da5fd9d347898f2fb797e2be58b3","2e2a0cfa6432432fb60492cc209ab526","d8f7d92c9bec4d3db7e0727a170905a1","eb40c267e3cf471dbb38223ab57ca909","87d51a0d4b544da88ce0e07a5a23efb5","b7c9dc7bce454a48bc91374b428a6107","a14df26cd1c84e3f81edbf22d9c59b1a","884138f40cbb495d91e48b080632337b","817e7306fe114da6969caa43beff6adc","d1a62489c654461c9d2da416130b11ef","cf5e0ba857da49f1a9de92d0fe3d760d","46e951d16fb14c6f9f1ff40efd1e935c","4696421a1037445a9f7a2664a859cce7","9e8091223f2a4aff8885e306f5c2e544","2e0a6ed9e9fa4bc6bd2baa89b09919ab","f332828d4c2440d4817543d1d51d8b9e","37e716c91f9e4843aad8766aa964a53c","9370d4f17e324b9e860eb0528510e966","590eb755593840458402d1b3354b5cae","3ee30a4c78e5414f8efd6677394abac8","acdb4896fd9c41878e1307b8ba5f29bc","e3c79d95b02943ae962607d792ebebfc","1a7729e7ce1b42d989bc425f91d54295","cce5b566462a49aea21c7a5db59f1304","608780bd020e4c69aeb144e42896c01e","756174d7e8574ff88be2a8ec0c852141","90cbcea9cc0d4e4f8fab2becbe263dc9","31415901414d48e59fd0978662b73dd9"]},"id":"h8hDmuJMxkZz","outputId":"21c3c66c-beb3-4da8-d8b0-b93f80e00017"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6597053837e49c5bfc6abdcb2cd5996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"947c1645128c4d80bb4baf508cd80a01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/11 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a14df26cd1c84e3f81edbf22d9c59b1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)l_00001-of-00010.bin:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9370d4f17e324b9e860eb0528510e966"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-52b2d2e382c4>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;31m# the device to load the model onto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m    \u001b[0;31m# load_in_4bit=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    572\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2992\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_sharded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;31m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2994\u001b[0;31m             resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n\u001b[0m\u001b[1;32m   2995\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2996\u001b[0m                 \u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# Load from URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m             cached_filename = cached_file(\n\u001b[0m\u001b[1;32m   1041\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mshard_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"downloading %s to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                 \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     def _raw_read(\n","\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["\n","text = \"<s>[INST] What is your favourite condiment? [/INST]\"\n","\"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> \"\n","\"[INST] Do you have mayonnaise recipes? [/INST]\"\n","\n","encodeds = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n","\n","model_inputs = encodeds.to(device)\n","model.to(device)\n","\n","generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True)\n","decoded = tokenizer.batch_decode(generated_ids)\n","print(decoded[0])"],"metadata":{"id":"KJLDIJ2JyAls"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a6597053837e49c5bfc6abdcb2cd5996":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f2935a997404d2bb2d08f0d7ffd2d60","IPY_MODEL_03a783b50be74bf9a9e97547ad1e424b","IPY_MODEL_e6c5ad3ed36b4125bb01f0acde059a5c"],"layout":"IPY_MODEL_dbee9553b87f442daa0d3d64a95df804"}},"3f2935a997404d2bb2d08f0d7ffd2d60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fbc4aece31546abbce9bbdcd352b2cd","placeholder":"​","style":"IPY_MODEL_6bf6a07df47149bfa8fb177032cf8342","value":"Downloading (…)lve/main/config.json: 100%"}},"03a783b50be74bf9a9e97547ad1e424b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f6a790133da475292389cfd91987321","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e4dc568fa354c52a94fbbda37c11017","value":571}},"e6c5ad3ed36b4125bb01f0acde059a5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0444bccad4424d4eb66e8350e39ce8e3","placeholder":"​","style":"IPY_MODEL_ca0f440c19d44fbc8885ad55f2669944","value":" 571/571 [00:00&lt;00:00, 8.75kB/s]"}},"dbee9553b87f442daa0d3d64a95df804":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fbc4aece31546abbce9bbdcd352b2cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bf6a07df47149bfa8fb177032cf8342":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f6a790133da475292389cfd91987321":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e4dc568fa354c52a94fbbda37c11017":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0444bccad4424d4eb66e8350e39ce8e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca0f440c19d44fbc8885ad55f2669944":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"947c1645128c4d80bb4baf508cd80a01":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9f287f8680945bebd452265a65f838c","IPY_MODEL_bd83476c5ea84a09a8196dcaf8ba5a84","IPY_MODEL_e62baa5a2fb6449cb7c5cf696b2b2e08"],"layout":"IPY_MODEL_fdc2bf14c2de4c66b786091afd510eea"}},"a9f287f8680945bebd452265a65f838c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3709da5fd9d347898f2fb797e2be58b3","placeholder":"​","style":"IPY_MODEL_2e2a0cfa6432432fb60492cc209ab526","value":"Downloading (…)model.bin.index.json: 100%"}},"bd83476c5ea84a09a8196dcaf8ba5a84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8f7d92c9bec4d3db7e0727a170905a1","max":23950,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb40c267e3cf471dbb38223ab57ca909","value":23950}},"e62baa5a2fb6449cb7c5cf696b2b2e08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87d51a0d4b544da88ce0e07a5a23efb5","placeholder":"​","style":"IPY_MODEL_b7c9dc7bce454a48bc91374b428a6107","value":" 23.9k/23.9k [00:00&lt;00:00, 616kB/s]"}},"fdc2bf14c2de4c66b786091afd510eea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3709da5fd9d347898f2fb797e2be58b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e2a0cfa6432432fb60492cc209ab526":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8f7d92c9bec4d3db7e0727a170905a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb40c267e3cf471dbb38223ab57ca909":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87d51a0d4b544da88ce0e07a5a23efb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7c9dc7bce454a48bc91374b428a6107":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a14df26cd1c84e3f81edbf22d9c59b1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_884138f40cbb495d91e48b080632337b","IPY_MODEL_817e7306fe114da6969caa43beff6adc","IPY_MODEL_d1a62489c654461c9d2da416130b11ef"],"layout":"IPY_MODEL_cf5e0ba857da49f1a9de92d0fe3d760d"}},"884138f40cbb495d91e48b080632337b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46e951d16fb14c6f9f1ff40efd1e935c","placeholder":"​","style":"IPY_MODEL_4696421a1037445a9f7a2664a859cce7","value":"Downloading shards:   0%"}},"817e7306fe114da6969caa43beff6adc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e8091223f2a4aff8885e306f5c2e544","max":11,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e0a6ed9e9fa4bc6bd2baa89b09919ab","value":0}},"d1a62489c654461c9d2da416130b11ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f332828d4c2440d4817543d1d51d8b9e","placeholder":"​","style":"IPY_MODEL_37e716c91f9e4843aad8766aa964a53c","value":" 0/11 [00:13&lt;?, ?it/s]"}},"cf5e0ba857da49f1a9de92d0fe3d760d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46e951d16fb14c6f9f1ff40efd1e935c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4696421a1037445a9f7a2664a859cce7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e8091223f2a4aff8885e306f5c2e544":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e0a6ed9e9fa4bc6bd2baa89b09919ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f332828d4c2440d4817543d1d51d8b9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37e716c91f9e4843aad8766aa964a53c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9370d4f17e324b9e860eb0528510e966":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_590eb755593840458402d1b3354b5cae","IPY_MODEL_3ee30a4c78e5414f8efd6677394abac8","IPY_MODEL_acdb4896fd9c41878e1307b8ba5f29bc"],"layout":"IPY_MODEL_e3c79d95b02943ae962607d792ebebfc"}},"590eb755593840458402d1b3354b5cae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a7729e7ce1b42d989bc425f91d54295","placeholder":"​","style":"IPY_MODEL_cce5b566462a49aea21c7a5db59f1304","value":"Downloading (…)l_00001-of-00010.bin:  60%"}},"3ee30a4c78e5414f8efd6677394abac8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_608780bd020e4c69aeb144e42896c01e","max":1543562713,"min":0,"orientation":"horizontal","style":"IPY_MODEL_756174d7e8574ff88be2a8ec0c852141","value":922746880}},"acdb4896fd9c41878e1307b8ba5f29bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90cbcea9cc0d4e4f8fab2becbe263dc9","placeholder":"​","style":"IPY_MODEL_31415901414d48e59fd0978662b73dd9","value":" 923M/1.54G [00:28&lt;00:05, 103MB/s]"}},"e3c79d95b02943ae962607d792ebebfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a7729e7ce1b42d989bc425f91d54295":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cce5b566462a49aea21c7a5db59f1304":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"608780bd020e4c69aeb144e42896c01e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"756174d7e8574ff88be2a8ec0c852141":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90cbcea9cc0d4e4f8fab2becbe263dc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31415901414d48e59fd0978662b73dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"364cc129003c4f22b73efda24ee932e8":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_9f166a05b3d346f69ff4024fa61777bc","IPY_MODEL_46abd6e14b70419493aa67fe41e70899","IPY_MODEL_995ad5d6ff2b4f83969527c9532e1297"],"layout":"IPY_MODEL_95da5740ec164a35aa8db658dde00d85"}},"3154519134bd4c2291b84379065c5d92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf032ff202ad437a818a8467f143ac84","placeholder":"​","style":"IPY_MODEL_715812fc6e7943e68a5c71200685fd31","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"baff13b3318745e0b6e086851fe67f9f":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_7a7ebd1b72a74aa98324440fd064fe7c","placeholder":"​","style":"IPY_MODEL_6512b4993a4d468f932e62af2e2a99d6","value":""}},"5a4e72c08e6744d7879c471134c61013":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_a7c92d9aebb2406fadc1d974da558db4","style":"IPY_MODEL_18d3379e32fc451cbf9f86e6344d1108","value":false}},"36af42c83c71419c87c31746e9c91d7e":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_a69926e3af894707807da9c769e16d50","style":"IPY_MODEL_a47a3276774f4d2081bd342049c8b8aa","tooltip":""}},"ae0a697605af46b49bd5b96bb794906c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0eb6ca866b7f416ab7d7fda966e8c3e8","placeholder":"​","style":"IPY_MODEL_6684b1f042d144409b2acd3a7004a045","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"95da5740ec164a35aa8db658dde00d85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"cf032ff202ad437a818a8467f143ac84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"715812fc6e7943e68a5c71200685fd31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a7ebd1b72a74aa98324440fd064fe7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6512b4993a4d468f932e62af2e2a99d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7c92d9aebb2406fadc1d974da558db4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18d3379e32fc451cbf9f86e6344d1108":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a69926e3af894707807da9c769e16d50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a47a3276774f4d2081bd342049c8b8aa":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"0eb6ca866b7f416ab7d7fda966e8c3e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6684b1f042d144409b2acd3a7004a045":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"653f7abbb89c40889afc7fa8a0ed0683":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53a9f06bca064525a81aa6396af16f0a","placeholder":"​","style":"IPY_MODEL_bf534e14402d4a0b80d86c323aa233e0","value":"Connecting..."}},"53a9f06bca064525a81aa6396af16f0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf534e14402d4a0b80d86c323aa233e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f166a05b3d346f69ff4024fa61777bc":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bd47c4983714045885441e0ebd4bdd5","placeholder":"​","style":"IPY_MODEL_f3ee70be37c541809d9a885b86a88bd2","value":"Token is valid (permission: write)."}},"46abd6e14b70419493aa67fe41e70899":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70a3f0ad705d4d8d98b76f0c03cb1d46","placeholder":"​","style":"IPY_MODEL_c5a46308a912423190947bd15f96eeb7","value":"Your token has been saved to /root/.cache/huggingface/token"}},"995ad5d6ff2b4f83969527c9532e1297":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c094178f63aa4044b7d20e74d1d8b1c8","placeholder":"​","style":"IPY_MODEL_5910058794024559a5ecc65acc013f97","value":"Login successful"}},"3bd47c4983714045885441e0ebd4bdd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3ee70be37c541809d9a885b86a88bd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70a3f0ad705d4d8d98b76f0c03cb1d46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5a46308a912423190947bd15f96eeb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c094178f63aa4044b7d20e74d1d8b1c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5910058794024559a5ecc65acc013f97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}